{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OAiaTMfjB-OM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID_FILE = \"covid.csv\"\n",
    "COVID_COLS = [\"CumulativePositive\", \"CumulativeDeceased\", \"CumulativeRecovered\", \"CurrentlyPositive\", \"Hospitalized\", \"IntensiveCare\"]\n",
    "POLICIES_COLS = [\"Curfew\"]\n",
    "COVARIATES_FOLDER = \"eurostat_datasets/\"\n",
    "POLICY_FILE = \"policies.csv\"\n",
    "DB_FILE = \"DB_finale_v3.xlsx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OSRP4t1MC8f2"
   },
   "outputs": [],
   "source": [
    "class Policies(object):\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "        self.df = self._load_df()\n",
    "            \n",
    "    def _load_df(self):\n",
    "        \"\"\"\n",
    "            Load and pre-process the policy file\n",
    "        \"\"\"\n",
    "        return pd.read_csv(self.file_name)\n",
    "    \n",
    "    def extract_policy_from_iso_a2_code(self, nuts2_code, iso_a2_code):\n",
    "        \"\"\"\n",
    "            Extract the policy from an ISO-A2 code\n",
    "        \"\"\"\n",
    "        out_df = self.df[self.df[\"province\"] == iso_a2_code][[\"date\"] + POLICIES_COLS]\n",
    "        out_df[\"NUTS\"] = nuts2_code\n",
    "        return out_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Hqjj2mlnC-Xd"
   },
   "outputs": [],
   "source": [
    "class CovidCases(object):\n",
    "    def __init__(self, covid_file_name):\n",
    "        self.covid_file_name = covid_file_name\n",
    "        self.df = self._load_df()\n",
    "        \n",
    "    def _load_df(self):\n",
    "        \"\"\"\n",
    "            Load and pre-process the file with Covid cases\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(self.covid_file_name)\n",
    "        df[COVID_COLS] = df[COVID_COLS].fillna(0)\n",
    "        return df\n",
    "    \n",
    "    def _find_children_from_nuts_2(self, nuts2_code, dataset_merger):\n",
    "        \"\"\"\n",
    "            From a nuts2_code, get all the children nuts3 codes\n",
    "            params:\n",
    "                nuts2_code: str\n",
    "                \n",
    "            return:\n",
    "                list (str)\n",
    "        \"\"\"\n",
    "        return dataset_merger.db_df[dm.db_df[\"NUTS\"] == nuts2_code][\"Covid (NUTS)\"].to_list()\n",
    "    \n",
    "    def _aggregate_from_nuts_2(self, nuts2_code, dataset_merger):\n",
    "        \"\"\"\n",
    "            Sum all covid cases from a nuts2_code aggregation\n",
    "            params:\n",
    "                nuts2_code: str\n",
    "            return:\n",
    "                DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        # Call _find_children_from_nuts_2(self, nuts2_code)\n",
    "        \n",
    "        # Sum all\n",
    "        covid_keys = self._find_children_from_nuts_2(nuts2_code, dataset_merger)\n",
    "        return self.df[self.df[\"NUTS\"].isin(covid_keys)].groupby([\"Date\"])[COVID_COLS].sum().reset_index()\n",
    "    \n",
    "    def get_covid_cases(self, covid_code, nuts2_code, dataset_merger):\n",
    "        \"\"\"\n",
    "            Get all covid cases\n",
    "            params:\n",
    "                covid_code: str\n",
    "                nuts2_code: str   \n",
    "        \"\"\"\n",
    "        \n",
    "        # If covid_code == nuts2_code, then just extract data from covid_code\n",
    "        # Else, call _aggregate_from_nuts_2 \n",
    "        out_df = None\n",
    "        if covid_code == nuts2_code:\n",
    "            out_df = self.df[self.df[\"NUTS\"] == nuts2_code][[\"Date\"] + COVID_COLS]\n",
    "        else:\n",
    "            out_df = self._aggregate_from_nuts_2(nuts2_code, dataset_merger)\n",
    "        \n",
    "        out_df[\"NUTS\"] = nuts2_code\n",
    "        return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MlrVgBbRDCP4"
   },
   "outputs": [],
   "source": [
    "class Covariate(object):\n",
    "    def __init__(self, file_name, file_type='xlsx', aggregation_method='sum'):\n",
    "        \"\"\"\n",
    "            Covariate file\n",
    "            params: \n",
    "                file_name: str\n",
    "                file_type: str\n",
    "                    among 'xlsx', 'tsv', 'csv'\n",
    "                aggregation_method: str\n",
    "                    among 'sum', 'popsum', 'avg'\n",
    "        \"\"\"\n",
    "        self.file_name = file_name\n",
    "        self.file_type = file_type\n",
    "        self.aggregation_method = aggregation_method\n",
    "        \n",
    "        self.col_name = '.'.join([file_name, file_type, aggregation_method])\n",
    "        \n",
    "        self.df = self._load_df()\n",
    "        \n",
    "    \n",
    "    def _load_df(self):\n",
    "        \"\"\"\n",
    "            Load the covariate data\n",
    "            \n",
    "            :return\n",
    "                DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        df = None\n",
    "        # Check the file type and load from the according file type\n",
    "        if self.file_type == \"xlsx\":\n",
    "            df = self._load_excel()\n",
    "        elif self.file_type == \"csv\":\n",
    "            df = self._load_csv()\n",
    "        elif self.file_type == \"tsv\":\n",
    "            df = self._load_tsv()\n",
    "            \n",
    "        return self._compute_covariate_value(df)\n",
    "        \n",
    "    \n",
    "    def _load_excel(self):\n",
    "        \"\"\"\n",
    "            Load from an .xlsx file\n",
    "            \n",
    "            :return\n",
    "                DataFrame\n",
    "        \"\"\"\n",
    "        return pd.read_excel(self.file_name)\n",
    "    \n",
    "    def _load_csv(self):\n",
    "        \"\"\"\n",
    "            Read from an .csv file\n",
    "            \n",
    "            :return\n",
    "                DataFrame\n",
    "        \"\"\"\n",
    "        return pd.read_csv(self.file_name)\n",
    "    \n",
    "    def _load_tsv(self):\n",
    "        \"\"\"\n",
    "            Read from an .tsv file\n",
    "            \n",
    "            :return\n",
    "                DataFrame\n",
    "        \"\"\"\n",
    "        return pd.read_csv(self.file_name, sep='\\t') \n",
    "    \n",
    "    @staticmethod\n",
    "    def _compute_covariate_value(df):\n",
    "        \"\"\"\n",
    "            Compute the covariate value by coalescing the columns from right-most to left-most\n",
    "            \n",
    "            :return\n",
    "                DataFrame\n",
    "        \"\"\"\n",
    "        return df.assign(\n",
    "            covariate_value=pd.to_numeric(df.iloc[:, ::-1].notnull().idxmax(1).pipe(\n",
    "                lambda d: df.lookup(d.index, d.values)\n",
    "            ), errors='coerce')\n",
    "        )\n",
    "    \n",
    "    def extract_covariate(self, nuts_codes):\n",
    "        \"\"\"\n",
    "            Extract the covariate value for given nuts_codes and a specified aggregartion method\n",
    "            \n",
    "            params:\n",
    "                nuts_codes: list (str)\n",
    "            \n",
    "            return:\n",
    "                DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        if len(nuts_codes) > 1:\n",
    "            return self.df[self.df.iloc[:, 0].isin(nuts_codes)][\"covariate_value\"].aggregate(self.aggregation_method)\n",
    "        else:\n",
    "            return self.df[self.df.iloc[:, 0] == nuts_codes[0]][\"covariate_value\"].values[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "k9ccGmO0DDgn"
   },
   "outputs": [],
   "source": [
    "class DatasetsMerger(object):\n",
    "    \n",
    "    def __init__(self, db_file_name, db_folder='./', db_sheet=3):\n",
    "        \"\"\"\n",
    "            DatasetMerger\n",
    "            \n",
    "            params:\n",
    "                db_file_name: str\n",
    "                db_folder: str\n",
    "        \"\"\"\n",
    "        self.db_file_name = db_file_name\n",
    "        self.db_folder = db_folder\n",
    "        self.db_sheet = db_sheet\n",
    "        self.db_df = self._load_db_df()\n",
    "        self.covariates = self._load_covariates()\n",
    "        self.covid_cases = self._load_covid_cases()\n",
    "        self.policies = self._load_policies()\n",
    "        \n",
    "        self._raw_data = {}\n",
    "    \n",
    "    def _load_db_df(self):\n",
    "        \"\"\"\n",
    "            Load the DBFinale\n",
    "            \n",
    "            returns:\n",
    "                DataFrame\n",
    "        \"\"\"\n",
    "        return pd.read_excel(self.db_file_name, sheet_name = self.db_sheet)\n",
    "    \n",
    "    def _load_covariates(self):\n",
    "        \"\"\"\n",
    "            Load all the covariates from the db_df\n",
    "            \n",
    "            return:\n",
    "                list (Covariate)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Return a map of {col_name_cov_1: Covariate(), col_name_cov_2: Covariate(), ...}\n",
    "        covs = {}\n",
    "        for covariate_info in list(self.db_df.columns.values)[8:]:\n",
    "            if \"inserire nome covariate\" in covariate_info:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                cov_file_name = covariate_info.split(\".\")[0]\n",
    "                cov_file_type = covariate_info.split(\".\")[1]\n",
    "                cov_agg_method = covariate_info.split(\".\")[2]\n",
    "                \n",
    "                covs[covariate_info] = Covariate(COVARIATES_FOLDER + cov_file_name + '.' + cov_file_type, file_type=cov_file_type, aggregation_method=cov_agg_method)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "        return covs\n",
    "            \n",
    "        \n",
    "    \n",
    "    def _load_covid_cases(self):\n",
    "        \"\"\"\n",
    "            Load Covid Cases\n",
    "            \n",
    "            return:\n",
    "                CovidCases\n",
    "        \"\"\"\n",
    "        \n",
    "        # Return CovidCases\n",
    "        return CovidCases(COVID_FILE)\n",
    "        \n",
    "    \n",
    "    def _load_policies(self):\n",
    "        \"\"\"\n",
    "            Load Policies\n",
    "            \n",
    "            return:\n",
    "                Policiesd4f\n",
    "        \"\"\"\n",
    "        \n",
    "        # Return Policies\n",
    "        return Policies(POLICY_FILE)\n",
    "        \n",
    "        \n",
    "    def merge(self):\n",
    "        \"\"\"\n",
    "            Merge the dataset\n",
    "            \n",
    "            return:\n",
    "                SQLLite Database\n",
    "        \"\"\"\n",
    "        all_policies = []\n",
    "        all_cov_values = []\n",
    "        all_covid_cases = []\n",
    "        \n",
    "        _already_seen_nuts = []\n",
    "        \n",
    "        # Loop over all the rows\n",
    "        for index, r in self.db_df.iterrows():\n",
    "            \n",
    "            if r[\"NUTS\"] in _already_seen_nuts:\n",
    "                continue\n",
    "            _already_seen_nuts.append(r[\"NUTS\"])\n",
    "                        \n",
    "            covid_infos = self.covid_cases.get_covid_cases(r[\"Covid (NUTS)\"], r[\"NUTS\"], self)\n",
    "            policies = self.policies.extract_policy_from_iso_a2_code(r[\"NUTS\"], r[\"ISO_A2 (FOR NATIONAL POLICIES)\"])\n",
    "            \n",
    "            all_policies.append(policies)\n",
    "            all_covid_cases.append(covid_infos)\n",
    "            \n",
    "            for cov_col_name, cov in self.covariates.items():\n",
    "                try:\n",
    "                    nuts_codes = list(map(lambda e: e.strip(), r[cov_col_name].split('/')))\n",
    "                    cov_value = cov.extract_covariate(nuts_codes)\n",
    "                    all_cov_values.append([r['Key'], cov_col_name.split(\".\")[0], cov_value])\n",
    "                except Exception:\n",
    "                    all_cov_values.append([r['Key'], cov_col_name.split(\".\")[0], None])\n",
    "                    \n",
    "        self._raw_data[\"policies\"] = all_policies\n",
    "        self._raw_data[\"covariates\"] = all_cov_values\n",
    "        self._raw_data[\"covid\"] = all_covid_cases\n",
    "        \n",
    "        \n",
    "    def save_to_sqlite(self):\n",
    "        \"\"\"\n",
    "            Save the data to SQLLite Format\n",
    "        \"\"\"\n",
    "        \n",
    "        to_store_covid = pd.concat(self._raw_data[\"covid\"])\n",
    "        to_store_covariates = pd.DataFrame(self._raw_data[\"covariates\"], columns=[\"NUTS\", \"Covariate\", \"Value\"])\n",
    "        to_store_policies = pd.concat(self._raw_data[\"policies\"])\n",
    "        \n",
    "        conn = sqlite3.connect('./covid_at_lombardy.sqlite')\n",
    "        to_store_covid.to_sql('covid_cases', conn, if_exists='replace', index=False)\n",
    "        to_store_covariates.to_sql('covariates', conn, if_exists='replace', index=False)\n",
    "        to_store_policies.to_sql('policies', conn, if_exists='replace', index=False)\n",
    "        \n",
    "                    \n",
    "                    \n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Your version of xlrd is 2.0.1. In xlrd >= 2.0, only the xls format is supported. Install openpyxl instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-89f875b7a02f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDatasetsMerger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDB_FILE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-70d4ac7709b1>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, db_file_name, db_folder, db_sheet)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb_folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb_sheet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb_sheet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_db_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcovariates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_covariates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcovid_cases\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_covid_cases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-70d4ac7709b1>\u001b[0m in \u001b[0;36m_load_db_df\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \"\"\"\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb_file_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb_sheet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_load_covariates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m                 )\n\u001b[0;32m    298\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"xls\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mxlrd_version\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;34m\"2\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1102\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m   1103\u001b[0m                     \u001b[1;34mf\"Your version of xlrd is {xlrd_version}. In xlrd >= 2.0, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m                     \u001b[1;34mf\"only the xls format is supported. Install openpyxl instead.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Your version of xlrd is 2.0.1. In xlrd >= 2.0, only the xls format is supported. Install openpyxl instead."
     ]
    }
   ],
   "source": [
    "dm = DatasetsMerger(DB_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.save_to_sqlite()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DatasetMerger.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
